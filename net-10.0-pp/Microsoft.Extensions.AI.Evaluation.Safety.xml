<?xml version="1.0" encoding="utf-8"?>
<doc>
  <assembly>
    <name>Microsoft.Extensions.AI.Evaluation.Safety</name>
  </assembly>
  <members>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.CodeVulnerabilityEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate code completion responses
            produced by an AI model for the presence of vulnerable code.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.CodeVulnerabilityEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate code completion responses
            produced by an AI model for the presence of vulnerable code.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.CodeVulnerabilityEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <param name="messages" />
      <param name="modelResponse" />
      <param name="chatConfiguration" />
      <param name="additionalContext" />
      <param name="cancellationToken" />
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.CodeVulnerabilityEvaluator.CodeVulnerabilityMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.CodeVulnerabilityEvaluator" />.</summary>
    </member>
    <member />
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator">
      <summary>
            An <see langword="abstract" /> base class that can be used to implement <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />s that utilize the
            Azure AI Content Safety service to evaluate responses produced by an AI model for the presence of a variety of
            harmful content such as violence, hate speech, etc.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="contentSafetyServiceMetricName">
            The name of the metric that should be used when this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the
            Azure AI Content Safety service to perform evaluations.</param>
      <param name="metricName">
            The name of the <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" /> produced by this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
      <param name="evaluatorName">The name of the derived <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration,System.String,System.String,System.String)">
      <summary>
            An <see langword="abstract" /> base class that can be used to implement <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />s that utilize the
            Azure AI Content Safety service to evaluate responses produced by an AI model for the presence of a variety of
            harmful content such as violence, hate speech, etc.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="contentSafetyServiceMetricName">
            The name of the metric that should be used when this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the
            Azure AI Content Safety service to perform evaluations.</param>
      <param name="metricName">
            The name of the <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" /> produced by this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
      <param name="evaluatorName">The name of the derived <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <param name="messages" />
      <param name="modelResponse" />
      <param name="chatConfiguration" />
      <param name="additionalContext" />
      <param name="cancellationToken" />
    </member>
    <member />
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator">
      <summary>
            An <see langword="abstract" /> base class that can be used to implement <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />s that utilize the
            Azure AI Content Safety service to evaluate responses produced by an AI model for the presence of a variety of
            unsafe content such as protected material, vulnerable code, harmful content etc.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="contentSafetyServiceAnnotationTask">
            The name of the annotation task that should be used when this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates
            with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="evaluatorName">The name of the derived <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration,System.String,System.String)">
      <summary>
            An <see langword="abstract" /> base class that can be used to implement <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />s that utilize the
            Azure AI Content Safety service to evaluate responses produced by an AI model for the presence of a variety of
            unsafe content such as protected material, vulnerable code, harmful content etc.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="contentSafetyServiceAnnotationTask">
            The name of the annotation task that should be used when this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates
            with the Azure AI Content Safety service to perform evaluations.</param>
      <param name="evaluatorName">The name of the derived <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> and the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluationTokenCounter"></xref> that should be used if the evaluation is performed using an AI model.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator.EvaluateContentSafetyAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,System.Collections.Generic.IEnumerable{System.String},System.String,System.String,System.Threading.CancellationToken)">
      <summary>
            Evaluates the supplied <paramref name="modelResponse" /> using the Azure AI Content Safety Service and returns
            an <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationResult" /> containing one or more <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" />s.</summary>
      <param name="messages">
            The conversation history including the request that produced the supplied <paramref name="modelResponse" />.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="additionalContext">
            Per conversation turn contextual information (beyond that which is available in <paramref name="messages" />)
            that the <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> may need to accurately evaluate the supplied
            <paramref name="modelResponse" />.</param>
      <param name="contentSafetyServicePayloadFormat">
            An identifier that specifies the format of the payload that should be used when communicating with the Azure AI
            Content Safety service to perform evaluations.</param>
      <param name="contentSafetyServiceMetricName">
            The name of the metric that should be used in the payload when communicating with the Azure AI Content Safety
            service to perform evaluations.</param>
      <param name="cancellationToken">
            A <see cref="T:System.Threading.CancellationToken" /> that can cancel the evaluation operation.</param>
      <returns>An <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationResult" /> containing one or more <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" />s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration">
      <summary>
            Specifies the Azure AI project that should be used and credentials that should be used when a
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</summary>
      <param name="credential">
            The Azure <see cref="T:Azure.Core.TokenCredential" /> that should be used when authenticating requests.</param>
      <param name="subscriptionId">
            The ID of the Azure subscription that contains the project identified by <paramref name="projectName" />.</param>
      <param name="resourceGroupName">
            The name of the Azure resource group that contains the project identified by <paramref name="projectName" />.</param>
      <param name="projectName">
            The name of the Azure AI project.</param>
      <param name="httpClient">
            The <see cref="T:System.Net.Http.HttpClient" /> that should be used when communicating with the Azure AI Content
            Safety service. While the parameter is optional, it is recommended to supply an
            <see cref="T:System.Net.Http.HttpClient" /> that is configured with robust resilience and retry policies.</param>
      <param name="timeoutInSecondsForRetries">
            The timeout (in seconds) after which a <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> should stop retrying failed attempts
            to communicate with the Azure AI Content Safety service when performing evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.#ctor(Azure.Core.TokenCredential,System.String,System.String,System.String,System.Net.Http.HttpClient,System.Int32)">
      <summary>
            Specifies the Azure AI project that should be used and credentials that should be used when a
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</summary>
      <param name="credential">
            The Azure <see cref="T:Azure.Core.TokenCredential" /> that should be used when authenticating requests.</param>
      <param name="subscriptionId">
            The ID of the Azure subscription that contains the project identified by <paramref name="projectName" />.</param>
      <param name="resourceGroupName">
            The name of the Azure resource group that contains the project identified by <paramref name="projectName" />.</param>
      <param name="projectName">
            The name of the Azure AI project.</param>
      <param name="httpClient">
            The <see cref="T:System.Net.Http.HttpClient" /> that should be used when communicating with the Azure AI Content
            Safety service. While the parameter is optional, it is recommended to supply an
            <see cref="T:System.Net.Http.HttpClient" /> that is configured with robust resilience and retry policies.</param>
      <param name="timeoutInSecondsForRetries">
            The timeout (in seconds) after which a <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> should stop retrying failed attempts
            to communicate with the Azure AI Content Safety service when performing evaluations.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.Credential">
      <summary>
            Gets the Azure <see cref="T:Azure.Core.TokenCredential" /> that should be used when authenticating requests.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.HttpClient">
      <summary>
            Gets the <see cref="T:System.Net.Http.HttpClient" /> that should be used when communicating with the Azure AI
            Content Safety service.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.ProjectName">
      <summary>
            Gets the name of the Azure AI project.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.ResourceGroupName">
      <summary>
            Gets the name of the Azure resource group that contains the project identified by <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.ProjectName" />.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.SubscriptionId">
      <summary>
            Gets the ID of the Azure subscription that contains the project identified by <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.ProjectName" />.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration.TimeoutInSecondsForRetries">
      <summary>
            Gets the timeout (in seconds) after which a <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> should stop retrying failed
            attempts to communicate with the Azure AI Content Safety service when performing evaluations.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate the groundedness of
            responses produced by an AI model.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate the groundedness of
            responses produced by an AI model.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> and the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluationTokenCounter"></xref> that should be used if the evaluation is performed using an AI model.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator.GroundednessProMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluatorContext">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator" /> uses to evaluate the groundedness of a
            response.</summary>
      <param name="groundingContext">
            Contextual information against which the groundedness of a response is evaluated.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluatorContext.#ctor(System.String)">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluator" /> uses to evaluate the groundedness of a
            response.</summary>
      <param name="groundingContext">
            Contextual information against which the groundedness of a response is evaluated.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.GroundednessProEvaluatorContext.GroundingContext">
      <summary>
            Gets the contextual information against which the groundedness of a response is evaluated.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of content that is hateful or unfair.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of content that is hateful or unfair.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator.HateAndUnfairnessMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of indirect attacks such as manipulated content, intrusion and information gathering.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of indirect attacks such as manipulated content, intrusion and information gathering.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> and the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluationTokenCounter"></xref> that should be used if the evaluation is performed using an AI model.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.IndirectAttackMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for presence of protected material.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for presence of protected material.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> and the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluationTokenCounter"></xref> that should be used if the evaluation is performed using an AI model.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.ProtectedArtworkMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator" /> for indicating presence of protected material in artwork in images.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.ProtectedFictionalCharactersMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator" /> for indicating presence of protected fictional characters in images.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.ProtectedLogosAndBrandsMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator" /> for indicating presence of protected logos and brands in images.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator.ProtectedMaterialMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ProtectedMaterialEvaluator" /> for indicating presence of protected material in responses.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of content that indicates self harm.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of content that indicates self harm.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator.SelfHarmMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of sexual content.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of sexual content.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator.SexualMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for presence of content that indicates ungrounded inference of human attributes.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for presence of content that indicates ungrounded inference of human attributes.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> and the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluationTokenCounter"></xref> that should be used if the evaluation is performed using an AI model.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator.UngroundedAttributesMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluatorContext">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator" /> uses to evaluate whether a response is
            ungrounded.</summary>
      <param name="groundingContext">
            Contextual information against which the groundedness (or ungroundedness) of a response is evaluated.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluatorContext.#ctor(System.String)">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluator" /> uses to evaluate whether a response is
            ungrounded.</summary>
      <param name="groundingContext">
            Contextual information against which the groundedness (or ungroundedness) of a response is evaluated.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.UngroundedAttributesEvaluatorContext.GroundingContext">
      <summary>
            Gets the contextual information against which the groundedness (or ungroundedness) of a response is evaluated.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of violent content.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator.#ctor(Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyServiceConfiguration)">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Content Safety service to evaluate responses produced by an
            AI model for the presence of violent content.</summary>
      <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator.ViolenceMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator" />.</summary>
    </member>
  </members>
</doc>